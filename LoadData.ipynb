{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ba3521-ea0e-4b10-aa02-6ee6dc9c4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cfgrib xarray matplotlib pandas\n",
    "# !pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29014fee-ec6c-4fae-8b76-f4d66c086a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cfgrib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44accf4-421f-4739-88f5-ad458a4ac9d4",
   "metadata": {},
   "source": [
    "### ERA5_Monthly_averaged_reanalysis_by_hour_of-day_data_on_single_levels_from_2013-2023.grib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc986bd-fa67-43b9-b599-d54bd33bc4de",
   "metadata": {},
   "source": [
    "#### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d8b82c-7d59-482a-bd61-f0c96482f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Path: C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\ERA5_Monthly_averaged_reanalysis_by_hour_of-day_data_on_single_levels_from_2013-2023.grib\n",
      "Updated Path: C:/Users/giann/OneDrive/Desktop/Thesis/Copernicus_Data/ERA5_Monthly_averaged_reanalysis_by_hour_of-day_data_on_single_levels_from_2013-2023.grib\n",
      "[<xarray.Dataset> Size: 220MB\n",
      "Dimensions:              (time: 528, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "    number               int32 4B 0\n",
      "  * time                 (time) datetime64[ns] 4kB 2013-01-01 ... 2023-12-01T...\n",
      "    step                 timedelta64[ns] 8B 00:00:00\n",
      "    depthBelowLandLayer  float64 8B 0.0\n",
      "  * latitude             (latitude) float64 1kB 72.0 71.75 71.5 ... 34.25 34.0\n",
      "  * longitude            (longitude) float64 3kB -25.0 -24.75 ... 59.75 60.0\n",
      "    valid_time           (time) datetime64[ns] 4kB 2013-01-01 ... 2023-12-01T...\n",
      "Data variables:\n",
      "    swvl1                (time, latitude, longitude) float32 110MB ...\n",
      "    stl1                 (time, latitude, longitude) float32 110MB ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts, <xarray.Dataset> Size: 110MB\n",
      "Dimensions:              (time: 528, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "    number               int32 4B 0\n",
      "  * time                 (time) datetime64[ns] 4kB 2013-01-01 ... 2023-12-01T...\n",
      "    step                 timedelta64[ns] 8B 00:00:00\n",
      "    depthBelowLandLayer  float64 8B 7.0\n",
      "  * latitude             (latitude) float64 1kB 72.0 71.75 71.5 ... 34.25 34.0\n",
      "  * longitude            (longitude) float64 3kB -25.0 -24.75 ... 59.75 60.0\n",
      "    valid_time           (time) datetime64[ns] 4kB ...\n",
      "Data variables:\n",
      "    swvl2                (time, latitude, longitude) float32 110MB ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts, <xarray.Dataset> Size: 661MB\n",
      "Dimensions:     (time: 528, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "    number      int32 4B 0\n",
      "  * time        (time) datetime64[ns] 4kB 2013-01-01 ... 2023-12-01T18:00:00\n",
      "    step        timedelta64[ns] 8B 00:00:00\n",
      "    surface     float64 8B 0.0\n",
      "  * latitude    (latitude) float64 1kB 72.0 71.75 71.5 71.25 ... 34.5 34.25 34.0\n",
      "  * longitude   (longitude) float64 3kB -25.0 -24.75 -24.5 ... 59.5 59.75 60.0\n",
      "    valid_time  (time) datetime64[ns] 4kB 2013-01-01 ... 2023-12-01T18:00:00\n",
      "Data variables:\n",
      "    slt         (time, latitude, longitude) float32 110MB ...\n",
      "    sp          (time, latitude, longitude) float32 110MB ...\n",
      "    u10         (time, latitude, longitude) float32 110MB ...\n",
      "    v10         (time, latitude, longitude) float32 110MB ...\n",
      "    t2m         (time, latitude, longitude) float32 110MB ...\n",
      "    d2m         (time, latitude, longitude) float32 110MB ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts, <xarray.Dataset> Size: 826MB\n",
      "Dimensions:     (time: 396, step: 2, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "    number      int32 4B 0\n",
      "  * time        (time) datetime64[ns] 3kB 2012-12-31T18:00:00 ... 2023-12-01T...\n",
      "  * step        (step) timedelta64[ns] 16B 06:00:00 12:00:00\n",
      "    surface     float64 8B 0.0\n",
      "  * latitude    (latitude) float64 1kB 72.0 71.75 71.5 71.25 ... 34.5 34.25 34.0\n",
      "  * longitude   (longitude) float64 3kB -25.0 -24.75 -24.5 ... 59.5 59.75 60.0\n",
      "    valid_time  (time, step) datetime64[ns] 6kB 2013-01-01 ... 2023-12-02T06:...\n",
      "Data variables:\n",
      "    smlt        (time, step, latitude, longitude) float32 165MB ...\n",
      "    e           (time, step, latitude, longitude) float32 165MB ...\n",
      "    ro          (time, step, latitude, longitude) float32 165MB ...\n",
      "    tp          (time, step, latitude, longitude) float32 165MB ...\n",
      "    pev         (time, step, latitude, longitude) float32 165MB ...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts]\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\ERA5_Monthly_averaged_reanalysis_by_hour_of-day_data_on_single_levels_from_2013-2023.grib\"\n",
    "\n",
    "# Replace backslashes with forward slashes\n",
    "updated_path = file_path.replace('\\\\', '/')\n",
    "\n",
    "# Print the updated path\n",
    "print(\"Original Path:\", file_path)\n",
    "print(\"Updated Path:\", updated_path)\n",
    "\n",
    "# Use open_datasets and NO open_dataset(from Error)\n",
    "datasets = cfgrib.open_datasets(updated_path)\n",
    "print(datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2821ee-7a49-464d-8412-8d817c755cf2",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf4125a-9b28-447d-8917-78108c4dd0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Dataset 0...\n",
      "Filled missing values.\n",
      "Step 3: Validated range for soil_temperature_level_1 (200K to 350K).\n",
      "Fixed missing time steps.\n",
      "Resampled data to monthly averages.\n",
      "Renamed variables.\n",
      "Updated metadata.\n",
      "\n",
      "Processed Dataset 0 Summary:\n",
      "<xarray.Dataset> Size: 55MB\n",
      "Dimensions:                        (time: 131, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "  * latitude                       (latitude) float64 1kB 72.0 71.75 ... 34.0\n",
      "  * longitude                      (longitude) float64 3kB -25.0 -24.75 ... 60.0\n",
      "    number                         int32 4B 0\n",
      "    step                           timedelta64[ns] 8B 00:00:00\n",
      "    depthBelowLandLayer            float64 8B 0.0\n",
      "  * time                           (time) datetime64[ns] 1kB 2013-01-31 ... 2...\n",
      "Data variables:\n",
      "    volumetric_soil_water_layer_1  (time, latitude, longitude) float32 27MB n...\n",
      "    soil_temperature_level_1       (time, latitude, longitude) float32 27MB n...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "\n",
      "Processing Dataset 1...\n",
      "Filled missing values.\n",
      "Fixed missing time steps.\n",
      "Resampled data to monthly averages.\n",
      "Renamed variables.\n",
      "Updated metadata.\n",
      "\n",
      "Processed Dataset 1 Summary:\n",
      "<xarray.Dataset> Size: 27MB\n",
      "Dimensions:                        (time: 131, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "  * latitude                       (latitude) float64 1kB 72.0 71.75 ... 34.0\n",
      "  * longitude                      (longitude) float64 3kB -25.0 -24.75 ... 60.0\n",
      "    number                         int32 4B 0\n",
      "    step                           timedelta64[ns] 8B 00:00:00\n",
      "    depthBelowLandLayer            float64 8B 7.0\n",
      "  * time                           (time) datetime64[ns] 1kB 2013-01-31 ... 2...\n",
      "Data variables:\n",
      "    volumetric_soil_water_layer_2  (time, latitude, longitude) float32 27MB n...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "\n",
      "Processing Dataset 2...\n",
      "Filled missing values.\n",
      "Step 3: Validated range for temperature_2m (200K to 350K).\n",
      "Step 3: Validated range for dewpoint_temperature_2m (200K to 350K).\n",
      "Converted temperature to Celsius.\n",
      "Converted surface pressure to hPa.\n",
      "Calculated wind speed.\n",
      "Fixed missing time steps.\n",
      "Resampled data to monthly averages.\n",
      "Renamed variables.\n",
      "Updated metadata.\n",
      "\n",
      "Processed Dataset 2 Summary:\n",
      "<xarray.Dataset> Size: 191MB\n",
      "Dimensions:                  (time: 131, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "  * latitude                 (latitude) float64 1kB 72.0 71.75 ... 34.25 34.0\n",
      "  * longitude                (longitude) float64 3kB -25.0 -24.75 ... 59.75 60.0\n",
      "    number                   int32 4B 0\n",
      "    step                     timedelta64[ns] 8B 00:00:00\n",
      "    surface                  float64 8B 0.0\n",
      "  * time                     (time) datetime64[ns] 1kB 2013-01-31 ... 2023-11-30\n",
      "Data variables:\n",
      "    soil_type                (time, latitude, longitude) float32 27MB nan ......\n",
      "    surface_pressure         (time, latitude, longitude) float32 27MB nan ......\n",
      "    wind_u_component         (time, latitude, longitude) float32 27MB nan ......\n",
      "    wind_v_component         (time, latitude, longitude) float32 27MB nan ......\n",
      "    temperature_2m           (time, latitude, longitude) float32 27MB nan ......\n",
      "    dewpoint_temperature_2m  (time, latitude, longitude) float32 27MB nan ......\n",
      "    wind_speed               (time, latitude, longitude) float32 27MB nan ......\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "\n",
      "Processing Dataset 3...\n",
      "Filled missing values.\n",
      "Step 3: Validated range for total_precipitation (>= 0).\n",
      "Fixed missing time steps.\n",
      "Resampled data to monthly averages.\n",
      "Renamed variables.\n",
      "Updated metadata.\n",
      "\n",
      "Processed Dataset 3 Summary:\n",
      "<xarray.Dataset> Size: 275MB\n",
      "Dimensions:                (time: 132, step: 2, latitude: 153, longitude: 341)\n",
      "Coordinates:\n",
      "  * step                   (step) timedelta64[ns] 16B 06:00:00 12:00:00\n",
      "  * latitude               (latitude) float64 1kB 72.0 71.75 71.5 ... 34.25 34.0\n",
      "  * longitude              (longitude) float64 3kB -25.0 -24.75 ... 59.75 60.0\n",
      "    number                 int32 4B 0\n",
      "    surface                float64 8B 0.0\n",
      "  * time                   (time) datetime64[ns] 1kB 2012-12-31 ... 2023-11-30\n",
      "Data variables:\n",
      "    snowmelt               (time, step, latitude, longitude) float32 55MB nan...\n",
      "    evaporation            (time, step, latitude, longitude) float32 55MB nan...\n",
      "    runoff                 (time, step, latitude, longitude) float32 55MB nan...\n",
      "    total_precipitation    (time, step, latitude, longitude) float32 55MB nan...\n",
      "    potential_evaporation  (time, step, latitude, longitude) float32 55MB nan...\n",
      "Attributes:\n",
      "    GRIB_edition:            1\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define how to rename variables for clarity\n",
    "rename_dict = {\n",
    "    \"t2m\": \"temperature_2m\",\n",
    "    \"tp\": \"total_precipitation\",\n",
    "    \"u10\": \"wind_u_component\",\n",
    "    \"v10\": \"wind_v_component\",\n",
    "    \"d2m\": \"dewpoint_temperature_2m\",\n",
    "    \"sp\": \"surface_pressure\",\n",
    "    \"swvl1\": \"volumetric_soil_water_layer_1\",\n",
    "    \"swvl2\": \"volumetric_soil_water_layer_2\",\n",
    "    \"stl1\": \"soil_temperature_level_1\",\n",
    "    \"smlt\": \"snowmelt\",\n",
    "    \"pev\": \"potential_evaporation\",\n",
    "    \"e\": \"evaporation\",\n",
    "    \"ro\": \"runoff\",\n",
    "    \"slt\": \"soil_type\"\n",
    "}\n",
    "\n",
    "# Process each dataset\n",
    "for i, ds in enumerate(datasets):  # Loop through all datasets\n",
    "    print(f\"\\nProcessing Dataset {i}...\")  # Print which dataset is being processed\n",
    "\n",
    "    # Fill missing values\n",
    "    ds = ds.fillna(value=float(\"nan\"))  # Replace any missing values with NaN\n",
    "    print(\"Filled missing values.\")\n",
    "\n",
    "    # Remove duplicate time entries\n",
    "    time_index = pd.Index(ds.time.values)  # Convert the time data to a pandas index so it works\n",
    "    if time_index.duplicated().any():  # Check for duplicates\n",
    "        ds = ds.sel(time=~time_index.duplicated())  # Keep only unique time entries\n",
    "        print(\"Removed duplicate time steps.\")\n",
    "\n",
    "    # Validate variable ranges (only for specific variables)\n",
    "    for var in ds.variables:  # Loop through all variables in the dataset\n",
    "        if var in rename_dict:  # Check if the variable is in the rename list\n",
    "            if \"temperature\" in rename_dict[var]:  # For temperature variables\n",
    "                ds[var] = ds[var].where((ds[var] >= 200) & (ds[var] <= 350), float(\"nan\"))  # Keep valid ranges\n",
    "                print(f\"Step 3: Validated range for {rename_dict[var]} (200K to 350K).\")\n",
    "            elif \"precipitation\" in rename_dict[var]:  # For precipitation variables\n",
    "                ds[var] = ds[var].where(ds[var] >= 0, float(\"nan\"))  # Precipitation must be non-negative\n",
    "                print(f\"Step 3: Validated range for {rename_dict[var]} (>= 0).\")\n",
    "\n",
    "    # Convert units for certain variables\n",
    "    if \"t2m\" in ds.variables:  # Convert temperature from Kelvin to Celsius\n",
    "        ds[\"t2m\"] = ds[\"t2m\"] - 273.15\n",
    "        print(\"Converted temperature to Celsius.\")\n",
    "\n",
    "    if \"sp\" in ds.variables:  # Convert surface pressure from Pa to hPa\n",
    "        ds[\"sp\"] = ds[\"sp\"] / 100\n",
    "        print(\"Converted surface pressure to hPa.\")\n",
    "\n",
    "    if \"u10\" in ds.variables and \"v10\" in ds.variables:  # Calculate wind speed\n",
    "        ds[\"wind_speed\"] = (ds[\"u10\"]**2 + ds[\"v10\"]**2)**0.5\n",
    "        print(\"Calculated wind speed.\")\n",
    "\n",
    "    # Add missing time steps (if any)\n",
    "    expected_time = pd.date_range(start=str(ds.time.min().values), end=str(ds.time.max().values), freq=\"1M\")\n",
    "    if not ds.time.equals(expected_time):  # Check if any time steps are missing\n",
    "        ds = ds.reindex(time=expected_time)  # Add the missing time steps, filling with NaN\n",
    "        print(\"Fixed missing time steps.\")\n",
    "\n",
    "    # Resample data to monthly averages\n",
    "    ds = ds.resample(time=\"ME\").mean()  # Group data by month and calculate averages\n",
    "    print(\"Resampled data to monthly averages.\")\n",
    "\n",
    "    # Rename variables\n",
    "    existing_vars = set(ds.variables)  # Get the list of variables in this dataset\n",
    "    rename_vars = {k: v for k, v in rename_dict.items() if k in existing_vars}  # Find variables to rename\n",
    "    ds = ds.rename(rename_vars)  # Apply the renaming\n",
    "    print(\"Renamed variables.\")\n",
    "\n",
    "    # Update metadata for renamed variables\n",
    "    for var in ds.data_vars:  # Go through all variables in the dataset\n",
    "        if var in rename_dict.values():  # If the variable was renamed\n",
    "            ds[var].attrs[\"description\"] = f\"Cleaned variable: {var}\"  # Add a description\n",
    "    print(\"Updated metadata.\")\n",
    "\n",
    "    # Print the summary of the processed dataset\n",
    "    print(f\"\\nProcessed Dataset {i} Summary:\")  # Display a summary\n",
    "    print(ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e992e-de26-4aa7-b2d6-ab1d7db9a821",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e912404-87c4-480f-863c-9708ed12baeb",
   "metadata": {},
   "source": [
    "### Multi-model_seasonal_reforecasts_of_river_discharge_for Europe_2013-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b26eb-0aaa-4e88-aa93-318fd0760c1e",
   "metadata": {},
   "source": [
    "#### Combine Datasets & Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b3f099-825b-4394-bb79-f381d0824640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values for dataset with 25 members.\n",
      "Renamed variables for clarity.\n",
      "Updated metadata.\n",
      "Combined dataset with 25 members:\n",
      "<xarray.Dataset> Size: 1TB\n",
      "Dimensions:                       (step: 54, y: 950, x: 1000, member: 1200)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 8kB 5.498e+06 ... 7.525e+05\n",
      "  * x                             (x) float64 8kB 2.502e+06 ... 7.498e+06\n",
      "  * step                          (step) datetime64[ns] 432B 2013-01-31 ... 2...\n",
      "    number                        (member) int64 10kB dask.array<chunksize=(25,), meta=np.ndarray>\n",
      "Dimensions without coordinates: member\n",
      "Data variables:\n",
      "    rdis                          (step, y, x, member) float32 246GB dask.array<chunksize=(1, 950, 1000, 25), meta=np.ndarray>\n",
      "    latitude                      (member, step, y, x) float32 246GB dask.array<chunksize=(25, 1, 950, 1000), meta=np.ndarray>\n",
      "    longitude                     (member, step, y, x) float32 246GB dask.array<chunksize=(25, 1, 950, 1000), meta=np.ndarray>\n",
      "    lambert_azimuthal_equal_area  (member, step) float64 518kB -2.147e+09 ......\n",
      "    land_binary_mask              (member, step, y, x) float32 246GB dask.array<chunksize=(25, 1, 950, 1000), meta=np.ndarray>\n",
      "    upArea                        (member, step, y, x) float32 246GB dask.array<chunksize=(25, 1, 950, 1000), meta=np.ndarray>\n",
      "Attributes:\n",
      "    GRIB_edition:            2\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             WMO Grib2\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2021-11-05T06:22 GRIB to CDM+CF via cfgrib-0.9.9...\n",
      "Filled missing values for dataset with 51 members.\n",
      "Renamed variables for clarity.\n",
      "Updated metadata.\n",
      "Combined dataset with 51 members:\n",
      "<xarray.Dataset> Size: 2TB\n",
      "Dimensions:                       (step: 52, y: 950, x: 1000, member: 2346)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 8kB 5.498e+06 ... 7.525e+05\n",
      "  * x                             (x) float64 8kB 2.502e+06 ... 7.498e+06\n",
      "  * step                          (step) datetime64[ns] 416B 2017-01-31 ... 2...\n",
      "    number                        (member) int64 19kB dask.array<chunksize=(51,), meta=np.ndarray>\n",
      "Dimensions without coordinates: member\n",
      "Data variables:\n",
      "    rdis                          (step, y, x, member) float32 464GB dask.array<chunksize=(1, 950, 1000, 51), meta=np.ndarray>\n",
      "    latitude                      (member, step, y, x) float32 464GB dask.array<chunksize=(51, 1, 950, 1000), meta=np.ndarray>\n",
      "    longitude                     (member, step, y, x) float32 464GB dask.array<chunksize=(51, 1, 950, 1000), meta=np.ndarray>\n",
      "    lambert_azimuthal_equal_area  (member, step) float64 976kB -2.147e+09 ......\n",
      "    land_binary_mask              (member, step, y, x) float32 464GB dask.array<chunksize=(51, 1, 950, 1000), meta=np.ndarray>\n",
      "    upArea                        (member, step, y, x) float32 464GB dask.array<chunksize=(51, 1, 950, 1000), meta=np.ndarray>\n",
      "Attributes:\n",
      "    GRIB_edition:            2\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             WMO Grib2\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2021-11-05T12:08 GRIB to CDM+CF via cfgrib-0.9.9...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = r\"C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\Multi-model_seasonal_reforecasts_of_river_discharge_for Europe_2013-2020\"\n",
    "\n",
    "# Find all .nc files in the folder\n",
    "file_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")]\n",
    "\n",
    "# Fix the 'step' dimension and ensure it's unique\n",
    "def preprocess(ds):\n",
    "    if \"step\" in ds.coords and \"valid_time\" in ds.coords:\n",
    "        # Replace 'step' with 'valid_time'\n",
    "        ds = ds.assign_coords(step=(\"step\", ds[\"valid_time\"].values))\n",
    "    \n",
    "    # Deduplicate or aggregate 'step'\n",
    "    if \"step\" in ds.coords:\n",
    "        # Remove duplicates, keeping the first occurrence\n",
    "        _, index = np.unique(ds[\"step\"], return_index=True)\n",
    "        # ds = ds.isel(step=index) \n",
    "        ds = ds.groupby(\"step\").mean()\n",
    "    return ds\n",
    "\n",
    "# Categorize files by member size\n",
    "files_by_member_size = {25: [], 51: []}\n",
    "\n",
    "for file in file_list:\n",
    "    ds = xr.open_dataset(file)\n",
    "    member_size = ds.sizes.get('member', None)\n",
    "    if member_size == 25:\n",
    "        files_by_member_size[25].append(file)\n",
    "    elif member_size == 51:\n",
    "        files_by_member_size[51].append(file)\n",
    "\n",
    "# Combine datasets\n",
    "combined_datasets = {}\n",
    "\n",
    "for member_size, files in files_by_member_size.items():\n",
    "    if files:\n",
    "        # Use open_mfdataset to process files and reduce memory usage\n",
    "        \n",
    "        # Chunking divides the dataset into manageable parts based on one or more dimensions\n",
    "        # Each \"chunk\" is a smaller portion of the dataset, and operations are performed on these\n",
    "        # chunks sequentially or in parallel, which helps reduce memory usage and allows processing \n",
    "        # of datasets that are too large to fit into RAM.\n",
    "        ds = xr.open_mfdataset(\n",
    "            files,\n",
    "            preprocess=preprocess,\n",
    "            combine=\"nested\", #assumes that the files are ordered logically in the same way as the desired concatenation order\n",
    "            concat_dim=\"member\",\n",
    "            chunks={\"step\": 10}  \n",
    "        )\n",
    "        \n",
    "        # Sort the dataset by 'step' in ascending order\n",
    "        ds = ds.sortby(\"step\", ascending=True)\n",
    "\n",
    "        \n",
    "        # Fill missing values\n",
    "        ds = ds.fillna(float(\"nan\"))  # Replace missing data with NaN\n",
    "        print(f\"Filled missing values for dataset with {member_size} members.\")\n",
    "\n",
    "        # Validate data ranges\n",
    "        if \"discharge\" in ds.variables:  # Ensure river discharge is non-negative\n",
    "            ds[\"discharge\"] = ds[\"discharge\"].where(ds[\"discharge\"] >= 0, float(\"nan\"))\n",
    "            print(\"Validated river discharge values (>= 0).\")\n",
    "\n",
    "        if \"temperature\" in ds.variables:  # Ensure temperature is within a realistic range\n",
    "            ds[\"temperature\"] = ds[\"temperature\"].where((ds[\"temperature\"] >= 200) & (ds[\"temperature\"] <= 350), float(\"nan\"))\n",
    "            print(\"Validated temperature range (200K to 350K).\")\n",
    "\n",
    "        # Convert units\n",
    "        if \"temperature\" in ds.variables:  # Convert temperature from Kelvin to Celsius\n",
    "            ds[\"temperature\"] = ds[\"temperature\"] - 273.15\n",
    "            print(\"Converted temperature to Celsius.\")\n",
    "\n",
    "        if \"precipitation\" in ds.variables:  # Convert precipitation to millimeters\n",
    "            ds[\"precipitation\"] = ds[\"precipitation\"] * 1000\n",
    "            print(\"Converted precipitation to millimeters.\")\n",
    "\n",
    "        # Rename variables for clarity\n",
    "        rename_dict = {\n",
    "            \"discharge\": \"river_discharge\",\n",
    "            \"temperature\": \"air_temperature\",\n",
    "            \"precipitation\": \"total_precipitation\"\n",
    "        }\n",
    "        existing_vars = set(ds.variables)  # Get all variables in the dataset\n",
    "        rename_vars = {k: v for k, v in rename_dict.items() if k in existing_vars}  # Find variables to rename\n",
    "        ds = ds.rename(rename_vars)  # Apply the renaming\n",
    "        print(\"Renamed variables for clarity.\")\n",
    "\n",
    "        # Update metadata\n",
    "        for var in ds.data_vars:  # Add descriptions to all variables\n",
    "            ds[var].attrs[\"description\"] = f\"Cleaned variable: {var}\"\n",
    "        print(\"Updated metadata.\")\n",
    "\n",
    "        \n",
    "        combined_datasets[member_size] = ds\n",
    "        print(f\"Combined dataset with {member_size} members:\")\n",
    "        print(ds)\n",
    "    else:\n",
    "        print(f\"No datasets found with {member_size} members.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5a38a-e995-49cd-956e-86a5634bf98d",
   "metadata": {},
   "source": [
    "### Multi-model_seasonal_reforecasts_of_river_discharge_for Europe_2021-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b1dc4-3b7c-4b17-b4eb-cec303933cc3",
   "metadata": {},
   "source": [
    "#### See Dimension of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de67e42d-af30-4363-8902-d331bc4ed710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: fairCRPSS_seas5_EFAS_01_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 2: fairCRPSS_seas5_EFAS_02_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 3: fairCRPSS_seas5_EFAS_03_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 4: fairCRPSS_seas5_EFAS_04_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 5: fairCRPSS_seas5_EFAS_05_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 6: fairCRPSS_seas5_EFAS_06_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 7: fairCRPSS_seas5_EFAS_07_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 8: fairCRPSS_seas5_EFAS_08_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 9: fairCRPSS_seas5_EFAS_09_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 10: fairCRPSS_seas5_EFAS_10_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 11: fairCRPSS_seas5_EFAS_11_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 12: fairCRPSS_seas5_EFAS_12_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 13: rdis-p33_seas5_EFAS_01_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 12, 'x': 1000, 'y': 950})\n",
      "----------------------------------------\n",
      "Dataset 14: rdis-p66_seas5_EFAS_01_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 12, 'x': 1000, 'y': 950})\n",
      "----------------------------------------\n",
      "Dataset 15: rdis_seas5_EFAS_20210101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 16: rdis_seas5_EFAS_20210201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 17: rdis_seas5_EFAS_20210301_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 18: rdis_seas5_EFAS_20210401_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 19: rdis_seas5_EFAS_20210501_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 20: rdis_seas5_EFAS_20210601_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 21: rdis_seas5_EFAS_20210701_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 22: rdis_seas5_EFAS_20210801_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 23: rdis_seas5_EFAS_20210901_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 24: rdis_seas5_EFAS_20211001_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 25: rdis_seas5_EFAS_20211101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 26: rdis_seas5_EFAS_20211201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 27: rdis_seas5_EFAS_20220101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 28: rdis_seas5_EFAS_20220201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 29: rdis_seas5_EFAS_20220301_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 30: rdis_seas5_EFAS_20220401_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 31: rdis_seas5_EFAS_20220501_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 32: rdis_seas5_EFAS_20220601_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 33: rdis_seas5_EFAS_20220701_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 34: rdis_seas5_EFAS_20220801_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 35: rdis_seas5_EFAS_20220901_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 36: rdis_seas5_EFAS_20221001_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 37: rdis_seas5_EFAS_20221101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 38: rdis_seas5_EFAS_20221201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 39: rdis_seas5_EFAS_20230101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 40: rdis_seas5_EFAS_20230201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 41: rdis_seas5_EFAS_20230301_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 42: rdis_seas5_EFAS_20230401_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 43: rdis_seas5_EFAS_20230501_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 44: rdis_seas5_EFAS_20230601_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 45: rdis_seas5_EFAS_20230701_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 46: rdis_seas5_EFAS_20230801_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 47: rdis_seas5_EFAS_20230901_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 48: rdis_seas5_EFAS_20231001_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 49: rdis_seas5_EFAS_20231101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 50: rdis_seas5_EFAS_20231201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = r\"C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\Multi-model_seasonal_reforecasts_of_river_discharge_for Europe_2021-2023\"\n",
    "\n",
    "# Get the list of all .nc files in the folder\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".nc\")]\n",
    "\n",
    "# Go through each file and show its dimensions\n",
    "for idx, file_path in enumerate(file_list):\n",
    "    try:\n",
    "        # Open the dataset\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Print the file name and its dimensions\n",
    "        print(f\"Dataset {idx + 1}: {os.path.basename(file_path)}\")\n",
    "        print(ds.dims)  # Show dataset dimensions\n",
    "        print(\"-\" * 40)  # Add a separator for clarity\n",
    "\n",
    "        \n",
    "        # Close the dataset to free space in memory\n",
    "        ds.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02169dde-8779-4d5d-a488-5176d0fa5b93",
   "metadata": {},
   "source": [
    "#### Combine Datasets & Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65be6980-2ca5-48a4-a922-a8a782161eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets combined successfully!\n",
      "First combined dataset:\n",
      "<xarray.Dataset> Size: 5GB\n",
      "Dimensions:                       (time: 1, y: 950, x: 1000, step: 24,\n",
      "                                   member: 51)\n",
      "Coordinates:\n",
      "  * time                          (time) datetime64[ns] 8B 2016-01-01\n",
      "  * y                             (y) int32 4kB 5497500 5492500 ... 752500\n",
      "  * x                             (x) int32 4kB 2502500 2507500 ... 7497500\n",
      "  * step                          (step) float64 192B -8.031e+04 ... 9.956e+04\n",
      "    latitude                      (y, x) float32 4MB dask.array<chunksize=(950, 1000), meta=np.ndarray>\n",
      "    longitude                     (y, x) float32 4MB dask.array<chunksize=(950, 1000), meta=np.ndarray>\n",
      "    number                        (member) int64 408B dask.array<chunksize=(51,), meta=np.ndarray>\n",
      "    valid_time                    (step) datetime64[ns] 192B dask.array<chunksize=(7,), meta=np.ndarray>\n",
      "Dimensions without coordinates: member\n",
      "Data variables:\n",
      "    fairCRPSS                     (time, step, y, x) float32 91MB dask.array<chunksize=(1, 2, 950, 1000), meta=np.ndarray>\n",
      "    rdis                          (step, y, x, member) float32 5GB dask.array<chunksize=(7, 950, 1000, 51), meta=np.ndarray>\n",
      "    lambert_azimuthal_equal_area  (step, y, x) float64 182MB dask.array<chunksize=(24, 950, 1000), meta=np.ndarray>\n",
      "    land_binary_mask              (step, y, x) float32 91MB dask.array<chunksize=(7, 950, 1000), meta=np.ndarray>\n",
      "    upArea                        (step, y, x) float32 91MB dask.array<chunksize=(7, 950, 1000), meta=np.ndarray>\n",
      "    rdis-p33                      (step, y, x) float32 91MB dask.array<chunksize=(4, 950, 1000), meta=np.ndarray>\n",
      "    rdis-p66                      (step, y, x) float32 91MB dask.array<chunksize=(4, 950, 1000), meta=np.ndarray>\n",
      "Attributes:\n",
      "    conventions:   CF-1.7\n",
      "    centre_id:     ecmf\n",
      "    Institution:   European Centre for Medium-Range Weather Forecasts\n",
      "    date_created:  18-Jun-2021 09:59:10\n",
      "    processed:     True\n",
      "    description:   Cleaned dataset with missing values fixed and outliers rem...\n",
      "Datasets combined successfully!\n",
      "Second combined dataset:\n",
      "<xarray.Dataset> Size: 1GB\n",
      "Dimensions:                       (step: 7, y: 950, x: 1000, member: 51)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 8kB 5.498e+06 ... 7.525e+05\n",
      "  * x                             (x) float64 8kB 2.502e+06 ... 7.498e+06\n",
      "    number                        (member) int64 408B dask.array<chunksize=(51,), meta=np.ndarray>\n",
      "    latitude                      (y, x) float32 4MB dask.array<chunksize=(950, 1000), meta=np.ndarray>\n",
      "    longitude                     (y, x) float32 4MB dask.array<chunksize=(950, 1000), meta=np.ndarray>\n",
      "    valid_time                    (step) datetime64[ns] 56B dask.array<chunksize=(7,), meta=np.ndarray>\n",
      "  * step                          (step) float64 56B 0.0 31.0 ... 152.0 182.0\n",
      "Dimensions without coordinates: member\n",
      "Data variables:\n",
      "    rdis                          (step, y, x, member) float32 1GB dask.array<chunksize=(7, 950, 1000, 51), meta=np.ndarray>\n",
      "    lambert_azimuthal_equal_area  (step, y, x) float64 53MB dask.array<chunksize=(7, 950, 1000), meta=np.ndarray>\n",
      "    land_binary_mask              (step, y, x) float32 27MB dask.array<chunksize=(7, 950, 1000), meta=np.ndarray>\n",
      "    upArea                        (step, y, x) float32 27MB dask.array<chunksize=(7, 950, 1000), meta=np.ndarray>\n",
      "Attributes:\n",
      "    GRIB_edition:            2\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             WMO Grib2\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2023-12-10T12:56 GRIB to CDM+CF via cfgrib-0.9.9...\n",
      "    processed:               True\n",
      "    description:             Cleaned dataset with missing values fixed and ou...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Path to the folder containing the .nc files\n",
    "# folder_path = r\"C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\Multi-model_seasonal_reforecasts_of_river_discharge_for Europe_2021-2023\"\n",
    "\n",
    "# # Get a list of all .nc files in the folder\n",
    "# file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".nc\")]\n",
    "\n",
    "# # Function to preprocess each dataset before combining\n",
    "# def preprocess(ds):\n",
    "#     # Ensure 'longitude' and 'latitude' are coordinates (not just variables)\n",
    "#     if \"longitude\" not in ds.coords and \"longitude\" in ds.variables:\n",
    "#         ds = ds.set_coords(\"longitude\")\n",
    "#     if \"latitude\" not in ds.coords and \"latitude\" in ds.variables:\n",
    "#         ds = ds.set_coords(\"latitude\")\n",
    "\n",
    "#     # If 'step' dimension is missing but 'time' exists, create a dummy 'step'\n",
    "#     if \"step\" not in ds.sizes and \"time\" in ds.sizes:\n",
    "#         ds[\"step\"] = (\"time\", np.arange(ds.sizes[\"time\"]))  # Add sequential numbers as 'step'\n",
    "#         ds = ds.swap_dims({\"time\": \"step\"})  # Use 'step' as the main dimension instead of 'time'\n",
    "\n",
    "#     # If 'step' exists, adjust its values to be in days\n",
    "#     if \"step\" in ds.coords:\n",
    "#         step_values = ds[\"step\"].values\n",
    "#         # Convert 'step' values to days\n",
    "#         step_values_in_days = (step_values - step_values.min()) / (60 * 60 * 24 * 1e9)\n",
    "#         ds = ds.assign_coords(step=(\"step\", step_values_in_days.astype(\"float64\")))\n",
    "\n",
    "#         # Sort by 'step' and remove duplicates\n",
    "#         ds = ds.sortby(\"step\")\n",
    "#         _, index = np.unique(ds[\"step\"], return_index=True)\n",
    "#         ds = ds.isel(step=index)\n",
    "\n",
    "#     return ds\n",
    "\n",
    "# # Function to combine multiple datasets into one\n",
    "# def combine_datasets(files):\n",
    "#     try:\n",
    "#         # Use xarray to open and combine multiple files\n",
    "#         combined = xr.open_mfdataset(\n",
    "#             files,\n",
    "#             preprocess=preprocess,  # Preprocess each file before combining\n",
    "#             combine=\"by_coords\",    # Match data using their coordinates (like latitude, longitude)\n",
    "#             chunks={\"step\": 10}     # Break data into smaller pieces for faster processing\n",
    "#         )\n",
    "#         print(\"Datasets combined successfully!\")\n",
    "#         return combined\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error combining datasets: {e}\")\n",
    "#         return None\n",
    "\n",
    "# # Combine the first half of the files\n",
    "# ds_combined1 = combine_datasets(file_list[:16])  # Process first 16 files\n",
    "# if ds_combined1:\n",
    "#     print(\"First combined dataset:\")\n",
    "#     print(ds_combined1)\n",
    "\n",
    "# # Combine the second half of the files\n",
    "# ds_combined2 = combine_datasets(file_list[16:])  # Process remaining files\n",
    "# if ds_combined2:\n",
    "#     print(\"Second combined dataset:\")\n",
    "#     print(ds_combined2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Path to the folder with all .nc files\n",
    "folder_path = r\"C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\Multi-model_seasonal_reforecasts_of_river_discharge_for Europe_2021-2023\"\n",
    "\n",
    "# Get a list of all .nc files in the folder\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".nc\")]\n",
    "\n",
    "# Function to clean and prepare each dataset\n",
    "def preprocess(ds):\n",
    "    # Make sure 'longitude' and 'latitude' are treated as coordinates\n",
    "    if \"longitude\" not in ds.coords and \"longitude\" in ds.variables:\n",
    "        ds = ds.set_coords(\"longitude\")\n",
    "    if \"latitude\" not in ds.coords and \"latitude\" in ds.variables:\n",
    "        ds = ds.set_coords(\"latitude\")\n",
    "\n",
    "    # If 'step' is missing, create it from 'time'\n",
    "    if \"step\" not in ds.sizes and \"time\" in ds.sizes:\n",
    "        ds[\"step\"] = (\"time\", np.arange(ds.sizes[\"time\"]))  # Add step values\n",
    "        ds = ds.swap_dims({\"time\": \"step\"})  # Use 'step' instead of 'time'\n",
    "\n",
    "    # Convert 'step' values to days\n",
    "    if \"step\" in ds.coords:\n",
    "        step_values = ds[\"step\"].values\n",
    "        step_values_in_days = (step_values - step_values.min()) / (60 * 60 * 24 * 1e9)  # Convert to days\n",
    "        ds = ds.assign_coords(step=(\"step\", step_values_in_days.astype(\"float64\")))\n",
    "        ds = ds.sortby(\"step\")  # Sort steps by value\n",
    "\n",
    "    # Replace missing values with 0\n",
    "    ds = ds.fillna(0)\n",
    "\n",
    "    # Remove duplicate steps\n",
    "    if \"step\" in ds.dims:\n",
    "        _, index = np.unique(ds[\"step\"], return_index=True)\n",
    "        ds = ds.isel(step=index)\n",
    "\n",
    "    # Make sure values are within reasonable ranges\n",
    "    for var in ds.data_vars:\n",
    "        ds[var] = ds[var].clip(min=0)  # Set all negative values to 0\n",
    "\n",
    "    # Remove outliers (extreme values)\n",
    "    for var in ds.data_vars:\n",
    "        if isinstance(ds[var].data, np.ndarray):  # Only apply if not using dask\n",
    "            lower = ds[var].quantile(0.01).compute()\n",
    "            upper = ds[var].quantile(0.99).compute()\n",
    "            ds[var] = ds[var].where((ds[var] >= lower) & (ds[var] <= upper), np.nan)\n",
    "\n",
    "    # Make sure latitude and longitude values are valid\n",
    "    if \"latitude\" in ds.coords and \"longitude\" in ds.coords:\n",
    "        valid_lat = (ds[\"latitude\"] >= -90) & (ds[\"latitude\"] <= 90)\n",
    "        valid_lon = (ds[\"longitude\"] >= -180) & (ds[\"longitude\"] <= 180)\n",
    "        ds = ds.where(valid_lat.compute() & valid_lon.compute(), drop=True)  # Keep only valid coordinates\n",
    "\n",
    "    # Add metadata to show the dataset was cleaned\n",
    "    ds.attrs[\"processed\"] = \"True\"\n",
    "    ds.attrs[\"description\"] = \"Cleaned dataset with missing values fixed and outliers removed.\"\n",
    "\n",
    "    return ds\n",
    "\n",
    "# Function to combine multiple datasets into one\n",
    "def combine_datasets(files):\n",
    "    try:\n",
    "        # Open and combine datasets\n",
    "        combined = xr.open_mfdataset(\n",
    "            files,\n",
    "            preprocess=preprocess,  # Clean each dataset before combining\n",
    "            combine=\"by_coords\",    # Match datasets by their coordinates\n",
    "            chunks={}               # Avoid chunking issues\n",
    "        )\n",
    "        # Fix chunking along spatial dimensions to avoid errors\n",
    "        combined = combined.chunk({\"y\": -1, \"x\": -1})\n",
    "        print(\"Datasets combined successfully!\")\n",
    "        return combined\n",
    "    except Exception as e:\n",
    "        print(f\"Error combining datasets: {e}\")\n",
    "        return None\n",
    "\n",
    "# Combine the first half of the datasets\n",
    "ds_combined1 = combine_datasets(file_list[:16])  # Process the first set of files\n",
    "if ds_combined1:\n",
    "    print(\"First combined dataset:\")\n",
    "    print(ds_combined1)\n",
    "\n",
    "# Combine the second half of the datasets\n",
    "ds_combined2 = combine_datasets(file_list[16:])  # Process the second set of files\n",
    "if ds_combined2:\n",
    "    print(\"Second combined dataset:\")\n",
    "    print(ds_combined2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56226b-d500-4ca9-bfda-43eac07b97ba",
   "metadata": {},
   "source": [
    "### Climate_indicators_for_Europe_from_2013_to_2023_derived_from_reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b365668-7fe3-4223-b783-e3ff7358f670",
   "metadata": {},
   "source": [
    "#### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2afb1608-dd42-4c50-abf3-a55299b39bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets combined successfully!\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\Climate_indicators_for_Europe_from_2013_to_2023_derived_from_reanalysis\"\n",
    "\n",
    "# Find all .nc files in the folder\n",
    "file_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(\".nc\")]\n",
    "\n",
    "# Open and combine multiple datasets using nested merging\n",
    "combined_dataset = xr.open_mfdataset(file_list, combine='nested', concat_dim='step', coords='minimal')\n",
    "# Combine files in order\n",
    "# Merge along the 'step' dimension\n",
    "# Use only needed coordinates\n",
    "\n",
    "print(\"Datasets combined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2caccd-7807-45ea-ac90-15258430b3c9",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5403836-532a-474b-96ea-c8d1f5e6a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing values.\n",
      "Renamed variables for clarity.\n",
      "Updated metadata.\n",
      "\n",
      "Cleaned Dataset Summary:\n",
      "<xarray.Dataset> Size: 36GB\n",
      "Dimensions:      (step: 20, time: 1008, lat: 185, lon: 271)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 8kB 1940-01-01 1940-02-01 ... 2023-12-01\n",
      "  * lat          (lat) float64 1kB 26.5 26.75 27.0 27.25 ... 72.0 72.25 72.5\n",
      "  * lon          (lon) float64 2kB -22.0 -21.75 -21.5 -21.25 ... 45.0 45.25 45.5\n",
      "    realization  int64 8B 0\n",
      "Dimensions without coordinates: step\n",
      "Data variables:\n",
      "    t2m          (step, time, lat, lon) float64 8GB dask.array<chunksize=(1, 1008, 185, 271), meta=np.ndarray>\n",
      "    data         (step, time, lat, lon) float64 8GB dask.array<chunksize=(1, 1008, 185, 271), meta=np.ndarray>\n",
      "    tp           (step, time, lat, lon) float32 4GB dask.array<chunksize=(1, 1008, 185, 271), meta=np.ndarray>\n",
      "    cdd          (step, time, lat, lon) float64 8GB dask.array<chunksize=(1, 1008, 185, 271), meta=np.ndarray>\n",
      "    fwi          (step, time, lat, lon) float64 8GB dask.array<chunksize=(1, 516, 185, 271), meta=np.ndarray>\n",
      "Attributes:\n",
      "    Conventions:  CF-1.7\n",
      "    institution:  European Centre for Medium-Range Weather Forecasts\n",
      "    history:      2024-04-02T13:52 GRIB to CDM+CF via cfgrib-0.9.9.1/ecCodes-...\n",
      "    source:       ECMWF\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "combined_dataset = combined_dataset.fillna(float(\"nan\"))  # Replace missing values with NaN\n",
    "print(\"Filled missing values.\")\n",
    "\n",
    "# Validate data ranges. \n",
    "if \"temperature\" in combined_dataset.variables:\n",
    "    # Most global atmospheric temperatures fall between 200 K (-73C) and 350 K (77C)\n",
    "    combined_dataset[\"temperature\"] = combined_dataset[\"temperature\"].where(\n",
    "        (combined_dataset[\"temperature\"] >= 200) & (combined_dataset[\"temperature\"] <= 350), float(\"nan\")\n",
    "    )\n",
    "    print(\"Validated temperature range (200K to 350K).\")\n",
    "\n",
    "if \"precipitation\" in combined_dataset.variables:\n",
    "    # Precipitation cannot be negative\n",
    "    combined_dataset[\"precipitation\"] = combined_dataset[\"precipitation\"].where(\n",
    "        combined_dataset[\"precipitation\"] >= 0, float(\"nan\")\n",
    "    )\n",
    "    print(\"Validated precipitation (>= 0).\")\n",
    "\n",
    "# Convert units\n",
    "if \"temperature\" in combined_dataset.variables:\n",
    "    # Convert temperature from Kelvin to Celsius\n",
    "    combined_dataset[\"temperature\"] = combined_dataset[\"temperature\"] - 273.15\n",
    "    combined_dataset[\"temperature\"].attrs[\"units\"] = \"Celsius\"\n",
    "    print(\"Converted temperature to Celsius.\")\n",
    "\n",
    "if \"precipitation\" in combined_dataset.variables:\n",
    "     # Convert precipitation to millimeters\n",
    "    combined_dataset[\"precipitation\"] = combined_dataset[\"precipitation\"] * 1000\n",
    "    combined_dataset[\"precipitation\"].attrs[\"units\"] = \"mm\"\n",
    "    print(\"Converted precipitation to millimeters.\")\n",
    "\n",
    "# Rename variables for clarity\n",
    "# Example rename dictionary\n",
    "rename_dict = {\n",
    "    \"temperature\": \"air_temperature\",\n",
    "    \"precipitation\": \"total_precipitation\",\n",
    "    \"discharge\": \"river_discharge\"\n",
    "}\n",
    "# Get all variables in the dataset\n",
    "existing_vars = set(combined_dataset.variables)\n",
    "# Find variables to rename\n",
    "rename_vars = {k: v for k, v in rename_dict.items() if k in existing_vars}\n",
    "combined_dataset = combined_dataset.rename(rename_vars)\n",
    "print(\"Renamed variables for clarity.\")\n",
    "\n",
    "# Update metadata\n",
    "# Add descriptions to each variable\n",
    "for var in combined_dataset.data_vars:\n",
    "    combined_dataset[var].attrs[\"description\"] = f\"Cleaned variable: {var}\"\n",
    "print(\"Updated metadata.\")\n",
    "\n",
    "# Print the summary of the cleaned dataset\n",
    "print(\"\\nCleaned Dataset Summary:\")\n",
    "print(combined_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf22f92-6471-4aea-8fe0-e6477bd2ab9a",
   "metadata": {},
   "source": [
    "#### See Dimension of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8d59d0-2630-46dd-b547-e9696ba925e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: fairCRPSS_seas5_EFAS_01_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 2: fairCRPSS_seas5_EFAS_02_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 3: fairCRPSS_seas5_EFAS_03_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 4: fairCRPSS_seas5_EFAS_04_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 5: fairCRPSS_seas5_EFAS_05_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 6: fairCRPSS_seas5_EFAS_06_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 7: fairCRPSS_seas5_EFAS_07_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 8: fairCRPSS_seas5_EFAS_08_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 9: fairCRPSS_seas5_EFAS_09_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 10: fairCRPSS_seas5_EFAS_10_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 11: fairCRPSS_seas5_EFAS_11_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 12: fairCRPSS_seas5_EFAS_12_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 1, 'step': 7, 'y': 950, 'x': 1000})\n",
      "----------------------------------------\n",
      "Dataset 13: rdis-p33_seas5_EFAS_01_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 12, 'x': 1000, 'y': 950})\n",
      "----------------------------------------\n",
      "Dataset 14: rdis-p66_seas5_EFAS_01_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'time': 12, 'x': 1000, 'y': 950})\n",
      "----------------------------------------\n",
      "Dataset 15: rdis_seas5_EFAS_20210101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 16: rdis_seas5_EFAS_20210201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 17: rdis_seas5_EFAS_20210301_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 18: rdis_seas5_EFAS_20210401_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 19: rdis_seas5_EFAS_20210501_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 20: rdis_seas5_EFAS_20210601_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 21: rdis_seas5_EFAS_20210701_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 22: rdis_seas5_EFAS_20210801_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 23: rdis_seas5_EFAS_20210901_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 24: rdis_seas5_EFAS_20211001_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 25: rdis_seas5_EFAS_20211101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 26: rdis_seas5_EFAS_20211201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 27: rdis_seas5_EFAS_20220101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 28: rdis_seas5_EFAS_20220201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 29: rdis_seas5_EFAS_20220301_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 30: rdis_seas5_EFAS_20220401_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 31: rdis_seas5_EFAS_20220501_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 32: rdis_seas5_EFAS_20220601_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 33: rdis_seas5_EFAS_20220701_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 34: rdis_seas5_EFAS_20220801_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 35: rdis_seas5_EFAS_20220901_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 36: rdis_seas5_EFAS_20221001_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 37: rdis_seas5_EFAS_20221101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 38: rdis_seas5_EFAS_20221201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 39: rdis_seas5_EFAS_20230101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 40: rdis_seas5_EFAS_20230201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 41: rdis_seas5_EFAS_20230301_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 42: rdis_seas5_EFAS_20230401_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 43: rdis_seas5_EFAS_20230501_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 44: rdis_seas5_EFAS_20230601_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 45: rdis_seas5_EFAS_20230701_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 46: rdis_seas5_EFAS_20230801_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 47: rdis_seas5_EFAS_20230901_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 48: rdis_seas5_EFAS_20231001_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 49: rdis_seas5_EFAS_20231101_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n",
      "Dataset 50: rdis_seas5_EFAS_20231201_v1.nc\n",
      "FrozenMappingWarningOnValuesAccess({'y': 950, 'x': 1000, 'member': 51, 'step': 7})\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"C:\\Users\\giann\\OneDrive\\Desktop\\Thesis\\Copernicus_Data\\Multi-model_seasonal_reforecasts_of_river_discharge_for Europe_2021-2023\"\n",
    "\n",
    "# Get the list of all .nc files in the folder\n",
    "file_list = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".nc\")]\n",
    "\n",
    "# Loop through each file and print its dimensions\n",
    "for idx, file_path in enumerate(file_list):\n",
    "    try:\n",
    "        # Open the dataset\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        \n",
    "        # Print the Dataset name and its dimensions\n",
    "        print(f\"Dataset {idx + 1}: {os.path.basename(file_path)}\")\n",
    "        print(ds.dims)  # Show dataset dimensions\n",
    "        print(\"-\" * 40)  # Add a separator for clarity\n",
    "        \n",
    "         # Close the dataset to save memory\n",
    "        ds.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c30c80-3df9-4c4c-ac84-27aff02228ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
